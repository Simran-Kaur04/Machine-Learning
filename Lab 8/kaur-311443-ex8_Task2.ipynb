{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: End-to-End Self-Driving via Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T21:23:29.255345Z",
     "iopub.status.busy": "2022-01-14T21:23:29.255032Z",
     "iopub.status.idle": "2022-01-14T21:23:29.261234Z",
     "shell.execute_reply": "2022-01-14T21:23:29.260358Z",
     "shell.execute_reply.started": "2022-01-14T21:23:29.255316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steering turning radius is stored as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T20:27:03.224918Z",
     "iopub.status.busy": "2022-01-14T20:27:03.224585Z",
     "iopub.status.idle": "2022-01-14T20:27:03.292252Z",
     "shell.execute_reply": "2022-01-14T20:27:03.291108Z",
     "shell.execute_reply.started": "2022-01-14T20:27:03.224886Z"
    }
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"/kaggle/input/car-steering-angle-prediction/driving_dataset/angles.txt\", header = None, sep = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 45000 images. We will keep first 25000 for training, next 10000 for validation and last 10000 for testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:16:48.755603Z",
     "iopub.status.busy": "2022-01-14T22:16:48.755165Z",
     "iopub.status.idle": "2022-01-14T22:16:48.766876Z",
     "shell.execute_reply": "2022-01-14T22:16:48.765963Z",
     "shell.execute_reply.started": "2022-01-14T22:16:48.755571Z"
    }
   },
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):#Inherits from torch.utils.data.Dataset\n",
    "    def __init__(self):\n",
    "        #default directory where data is loaded\n",
    "        self.filepath = '../input/car-steering-angle-prediction/driving_dataset/'\n",
    "#       From the directory stores first 25000 images for training\n",
    "        self.filenames = [self.filepath + target[0][i] for i in range(25000)]\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        filename = self.filenames[index]\n",
    "        img = cv2.imread(filename)\n",
    "        #Resizing images to(66,200)\n",
    "        resized = cv2.resize(img,(66,200),interpolation = cv2.INTER_AREA)\n",
    "        #normalizing image\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        transf_img = transform(resized)\n",
    "        mean, std = transf_img.mean([1,2]), transf_img.std([1,2])\n",
    "        transform_norm = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
    "        norm_img = transform_norm(resized)\n",
    "        #return the image converted to a numpy array and its corresponding steering angle\n",
    "        return norm_img.float(),target[1][index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:16:51.202367Z",
     "iopub.status.busy": "2022-01-14T22:16:51.201951Z",
     "iopub.status.idle": "2022-01-14T22:16:51.214501Z",
     "shell.execute_reply": "2022-01-14T22:16:51.213878Z",
     "shell.execute_reply.started": "2022-01-14T22:16:51.202338Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # first three convolution layer with 5*5 kernal and stride = 2\n",
    "        self.conv1 = nn.Conv2d(3, 24, 5, stride = (2,2))\n",
    "        self.conv2 = nn.Conv2d(24, 36, 5, stride = (2,2))\n",
    "        self.conv3 = nn.Conv2d(36, 48, 5, stride = (2,2))\n",
    "        # Next two convolution layer with 3*3 kernal and stride = 1\n",
    "        self.conv4 = nn.Conv2d(48, 64, 3, stride = (1,1))\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, stride = (1,1))\n",
    "        # flatten the image to pass\n",
    "        self.flat = nn.Linear(1152, 1164)\n",
    "        self.lin1 = nn.Linear(1164,100)\n",
    "        self.lin2 = nn.Linear(100, 50)\n",
    "        self.lin3 = nn.Linear(50, 10)\n",
    "        self.out = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.out(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:16:53.035070Z",
     "iopub.status.busy": "2022-01-14T22:16:53.034751Z",
     "iopub.status.idle": "2022-01-14T22:16:53.307103Z",
     "shell.execute_reply": "2022-01-14T22:16:53.306141Z",
     "shell.execute_reply.started": "2022-01-14T22:16:53.035037Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = Train_Dataset()\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size = 60, shuffle = True)\n",
    "net = ConvNet()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = 1e-3)\n",
    "criterion = torch.nn.MSELoss()               # Mean squared loss is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:16:53.647396Z",
     "iopub.status.busy": "2022-01-14T22:16:53.647069Z",
     "iopub.status.idle": "2022-01-14T22:33:48.405422Z",
     "shell.execute_reply": "2022-01-14T22:33:48.404480Z",
     "shell.execute_reply.started": "2022-01-14T22:16:53.647361Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(4):\n",
    "    avg_train_rmse = []\n",
    "    for i,sample_batched in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        yhat = net(sample_batched[0])\n",
    "        loss = criterion(yhat.squeeze(),sample_batched[1].type(torch.float))\n",
    "        avg_train_rmse.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    print(f'Avg RMSE after epoch {epoch} is {(sum(avg_train_rmse)**(0.5))/len(avg_train_rmse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg RMSE after epoch 0 is 1.5243878364562988\n",
    "\n",
    "Avg RMSE after epoch 1 is 1.499646782875061\n",
    "\n",
    "Avg RMSE after epoch 2 is 1.4494885206222534\n",
    "\n",
    "Avg RMSE after epoch 3 is 1.387422800064087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:33:58.236251Z",
     "iopub.status.busy": "2022-01-14T22:33:58.235119Z",
     "iopub.status.idle": "2022-01-14T22:33:58.248019Z",
     "shell.execute_reply": "2022-01-14T22:33:58.246778Z",
     "shell.execute_reply.started": "2022-01-14T22:33:58.236194Z"
    }
   },
   "outputs": [],
   "source": [
    "class Val_Dataset(Dataset):#Inherits from torch.utils.data.Dataset\n",
    "    def __init__(self):\n",
    "        #default directory where data is loaded\n",
    "        self.filepath = '../input/car-steering-angle-prediction/driving_dataset/'\n",
    "#         self.filenames = os.listdir(self.filepath)\n",
    "        self.filenames = [self.filepath + target[0][i] for i in range(25000, 35000)]\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        filename = self.filenames[index]\n",
    "        img = cv2.imread(filename)\n",
    "        #Resizing images to(66,200)\n",
    "        resized = cv2.resize(img,(66,200),interpolation = cv2.INTER_AREA)\n",
    "        #normalizing image\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        transf_img = transform(resized)\n",
    "        mean, std = transf_img.mean([1,2]), transf_img.std([1,2])\n",
    "        transform_norm = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
    "        norm_img = transform_norm(resized)\n",
    "        #return the image converted to a numpy array and its corresponding steering angle\n",
    "        return norm_img.float(),target[1][index] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:34:00.874281Z",
     "iopub.status.busy": "2022-01-14T22:34:00.873964Z",
     "iopub.status.idle": "2022-01-14T22:35:52.662528Z",
     "shell.execute_reply": "2022-01-14T22:35:52.661505Z",
     "shell.execute_reply.started": "2022-01-14T22:34:00.874250Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data = Val_Dataset()\n",
    "val_loader = torch.utils.data.DataLoader(val_data,batch_size = 60, shuffle = True)\n",
    "\n",
    "avg_val_rmse = []\n",
    "for i,sample_batched in enumerate(val_loader):\n",
    "    yhat_val = net(sample_batched[0])\n",
    "    loss_val = criterion(yhat_val.squeeze(),sample_batched[1].type(torch.float))\n",
    "    avg_val_rmse.append(loss_val)\n",
    "print(f'Avg RMSE on validation set is {(sum(avg_val_rmse)**(0.5))/len(avg_val_rmse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg RMSE on validation set is 5.460453033447266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:36:11.433609Z",
     "iopub.status.busy": "2022-01-14T22:36:11.432502Z",
     "iopub.status.idle": "2022-01-14T22:36:11.444958Z",
     "shell.execute_reply": "2022-01-14T22:36:11.443966Z",
     "shell.execute_reply.started": "2022-01-14T22:36:11.433554Z"
    }
   },
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):#Inherits from torch.utils.data.Dataset\n",
    "    def __init__(self):\n",
    "        #default directory where data is loaded\n",
    "        self.filepath = '../input/car-steering-angle-prediction/driving_dataset/'\n",
    "#         self.filenames = os.listdir(self.filepath)\n",
    "        self.filenames = [self.filepath + target[0][i] for i in range(35000, 45406)]\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        filename = self.filenames[index]\n",
    "        img = cv2.imread(filename)\n",
    "        #Resizing images to(66,200)\n",
    "        resized = cv2.resize(img,(66,200),interpolation = cv2.INTER_AREA)\n",
    "        #normalizing image\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        transf_img = transform(resized)\n",
    "        mean, std = transf_img.mean([1,2]), transf_img.std([1,2])\n",
    "        transform_norm = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
    "        norm_img = transform_norm(resized)\n",
    "        #return the image converted to a numpy array and its corresponding steering angle\n",
    "        return norm_img.float(),target[1][index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:36:15.265598Z",
     "iopub.status.busy": "2022-01-14T22:36:15.264623Z",
     "iopub.status.idle": "2022-01-14T22:37:28.075058Z",
     "shell.execute_reply": "2022-01-14T22:37:28.074166Z",
     "shell.execute_reply.started": "2022-01-14T22:36:15.265526Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = Test_Dataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size = 60, shuffle = True)\n",
    "\n",
    "avg_test_rmse = []\n",
    "for i,sample_batched in enumerate(test_loader):\n",
    "    yhat_test = net(sample_batched[0])\n",
    "    loss_test = criterion(yhat_test.squeeze(),sample_batched[1].type(torch.float))\n",
    "    avg_test_rmse.append(loss_test)\n",
    "print(f'Avg RMSE on Test set is {(sum(avg_test_rmse)**(0.5))/len(avg_test_rmse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg RMSE on Test set is 4.780969142913818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For normalization Link used:\n",
    "https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
